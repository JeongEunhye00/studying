{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbcbc1cd",
   "metadata": {},
   "source": [
    "# <span style=\"color:#2834d4\">전체 구조</span>\n",
    "\n",
    "<img src=\"img/affine_ex.png\" width=\"70%\" height=\"70%\" align=\"left\">\n",
    "<img src=\"img/cnn_ex.png\" width=\"70%\" height=\"70%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef31044",
   "metadata": {},
   "source": [
    "- CNN에서는 convolutional layer와 pooling layer가 새롭게 등장함\n",
    "- 출력과 가까운 층에서는 Affine-ReLU의 구성을 사용할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ae0af1",
   "metadata": {},
   "source": [
    "# <span style=\"color:#2834d4\">합성곱 계층</span>\n",
    "\n",
    "- 합성곱 계층의 입출력 데이터를 특징 맵(feature map)이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f3611d",
   "metadata": {},
   "source": [
    "## 1. 완전연결 계층의 문제점\n",
    "\n",
    "- 데이터의 형상이 무시됨\n",
    "    - ex) 이미지의 경우 3차원을 1차원으로 평탄화한 후 입력하기 때문에, 공간적 정보를 살릴 수 없게됨.\n",
    "- 그러나 합성곱 계층은 형상을 유지함\n",
    "    - ex) 이미지의 경우 3차원 데이터로 입력받고, 다음 계층에서도 3차원 데이터로 전달하여 이미지처럼 형상을 가진 데이터를 제대로 이해할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc063b4",
   "metadata": {},
   "source": [
    "## 2. 합성곱 (convolution) 연산 \n",
    "\n",
    "<img src=\"img/conv_ex.png\" width=\"40%\" height=\"40%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb556e3e",
   "metadata": {},
   "source": [
    "- 필터(=커널)의 윈도우를 일정 간격으로 이동해가며 입력데이터에 적용함\n",
    "- 입력과 필터에서 대응하는 원소끼리 곱한 후 그 총합을 구하고, 그 결과를 출력의 해당 장소에 저장함\n",
    "\n",
    "<img src=\"img/conv_bias.png\" width=\"70%\" height=\"70%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826cbabb",
   "metadata": {},
   "source": [
    "- CNN에서는 필터의 매개변수가 그동안의 가중치에 해당하고, 편향도 존재함\n",
    "    - 편향은 항상 하나(1x1)만 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d451285f",
   "metadata": {},
   "source": [
    "## 3. 패딩 (padding)\n",
    "\n",
    "<img src=\"img/padding.png\" width='70%' heigth='70%' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca186b8",
   "metadata": {},
   "source": [
    "- 합성곱 연산을 하기 전에 입력 데이터 주변을 특정 값(예컨대 0)으로 채우는 것\n",
    "- 주로 출력 크기를 조정할 목적으로 사용함\n",
    "    - 입력 데이터의 공간적 크기를 고정한 채로 다음 계층에 전달할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afea9d06",
   "metadata": {},
   "source": [
    "## 4. 스트라이드 (stride)\n",
    "\n",
    "- 필터를 적용하는 간격을 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e3f23",
   "metadata": {},
   "source": [
    "### ※출력 크기 계산\n",
    "## $O = \\frac{I \\ + \\ 2P \\ - \\ F}{S} + 1$\n",
    "\n",
    "- 입력크기-$I$, 필터크기-$F$, 출력크기-$O$, 패딩-$P$, 스트라이드-$S$\n",
    "- 단, $\\frac{I \\ + \\ 2P \\ - \\ F}{S}$ 가 정수로 나누어 떨어지는 값이어야 함\n",
    "    - 정수가 아닐 경우 반올림이나 특별히 에러를 내지 않고 진행하도록 구현하는 경우도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d122300",
   "metadata": {},
   "source": [
    "## 5. 3차원 데이터의 합성곱 연산\n",
    "\n",
    "<img src=\"img/conv_ex_3d.png\" width=\"50%\" height=\"50%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6781d",
   "metadata": {},
   "source": [
    "- 입력 데이터의 채널 수와 필터의 채널 수가 같아야 함\n",
    "- 모든 채널의 필터가 같은 크기여야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab9673a",
   "metadata": {},
   "source": [
    "## 6. 블록으로 생각하기\n",
    "\n",
    "- 채널수 $C$, 높이 $H$, 너비 $W$, 필터 $F$ 데이터 수 $N$\n",
    "- 3차원 데이터 $\\to \\ (C, H, W)$, 필터도 같은 순서로 $(C, FH, FW)$\n",
    "\n",
    "**하나의 필터만 사용한 경우**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24e3e19",
   "metadata": {},
   "source": [
    "<img src=\"img/conv_block_f1.png\" width=\"50%\" height=\"50%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b30d79",
   "metadata": {},
   "source": [
    "**여러 필터를 사용한 경우**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f246c549",
   "metadata": {},
   "source": [
    "<img src=\"img/conv_block_fn.png\" width=\"50%\" height=\"50%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dea5058",
   "metadata": {},
   "source": [
    "**bias 추가한 경우**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c184a",
   "metadata": {},
   "source": [
    "<img src=\"img/conv_block_bias.png\" width=\"60%\" height=\"60%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530d6b15",
   "metadata": {},
   "source": [
    "**배치 처리한 경우**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9454ca",
   "metadata": {},
   "source": [
    "<img src=\"img/conv_block_batch.png\" width=\"60%\" height=\"60%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36cc0c3",
   "metadata": {},
   "source": [
    "# <span style=\"color:#2834d4\">풀링 계층</span>\n",
    "- 세로 가로 방향의 공간을 줄이는 연산\n",
    "- 종류: max pooling(대상 영역에서 최댓값을 취하는 연산), average pooling(대상 영역의 평균 계산) 등\n",
    "- 풀링의 윈도우 크기와 스트라이드는 같은 값으로 설정하는 것이 보통임\n",
    "\n",
    "max pooling 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d8942",
   "metadata": {},
   "source": [
    "<img src=\"img/max_pool.png\" width =\"50%\" height=\"50%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1daff2",
   "metadata": {},
   "source": [
    "## 1. 풀링 계층의 특징\n",
    "\n",
    "- 학습해야할 매개변수가 없음\n",
    "- 채널 수가 변하지 않음\n",
    "    - 채널마다 독립적으로 계산하기 때문\n",
    "- 입력의 변화에 영향을 적게 받음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f8533",
   "metadata": {},
   "source": [
    "# <span style=\"color:#2834d4\">합성곱/풀링 계층 구현하기</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8014b9",
   "metadata": {},
   "source": [
    "## 1. im2col로 데이터 전개하기\n",
    "\n",
    "<img src=\"img/im2col.png\" width=\"40%\" height=\"40%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5644485",
   "metadata": {},
   "source": [
    "- 입력 데이터를 필터링(가중치 계산)하기 좋게 전개하는 함수\n",
    "    - 입력 데이터에서 필터를 적용하는 영역을 한 줄로 늘어놓는데, 이 전개를 필터를 적용하는 모든 영역에서 수행\n",
    "- 배치 안의 데이터 수까지 포함한 4차원 데이터를 2차원으로 변환\n",
    "- 필터 적용 영역이 겹치게 되면 원소 수가 원래 블록의 원소 수보다 많아져서 메모리를 더 많이 소비한다는 단점이 있음\n",
    "    - 그러나 컴퓨터는 큰 행렬을 묶어서 계산하는데 탁월. 선형대수 라이브러리를 활용해 효율을 높일 수 있음\n",
    "    \n",
    "<img src=\"img/im2col_.png\" width=\"60%\" height=\"60%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed2c0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    N, C, H, W = input_data.shape  # (이미지 수, 채널 수, 높이, 너비)\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')  # 각 axis의 edge에 pad만큼 패딩\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col  # 2차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1a7daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x1 = np.random.rand(1, 3, 7, 7)  # (데이터수, 채널수, 높이, 너비)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "print(col1.shape)\n",
    "\n",
    "x2 = np.random.rand(10, 3, 7, 7)  # 데이터 10개\n",
    "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a32a5f",
   "metadata": {},
   "source": [
    "## 2. 합성곱 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed58cb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T  # 필터 전개\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W) 로 축 순서 변경\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7691c53a",
   "metadata": {},
   "source": [
    "## 3. 풀링 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2afcd1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        \n",
    "        out = np.max(col, axis=1)  # 지정한 차원의 축마다 최댓값 구함\n",
    "        \n",
    "        out = np.reshpae(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf454522",
   "metadata": {},
   "source": [
    "# <span style=\"color:#2834d4\">CNN 구현하기</span>\n",
    "\n",
    "단순한 CNN 네트워크 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cddeef",
   "metadata": {},
   "source": [
    "<img src='img/simpleCNN.png' width='50%' height='50%' align='left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ba98ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "\n",
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim=(1,28,28),\n",
    "                conv_param={'filter_num':30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "        \n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "        \n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'], conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        self.loss(x, t)\n",
    "        \n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Conv1'].dW\n",
    "        grads['b1'] = self.layers['Conv1'].db\n",
    "        grads['W2'] = self.layers['Affine1'].dW\n",
    "        grads['b2'] = self.layers['Affine1'].db\n",
    "        grads['W3'] = self.layers['Affine2'].dW\n",
    "        grads['b3'] = self.layers['Affine2'].db\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : \n",
    "            t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1527a964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 10\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6cac43",
   "metadata": {},
   "source": [
    "=== epoch:1, train acc:0.455, test acc:0.409 ===<br>\n",
    "=== epoch:2, train acc:0.809, test acc:0.794 ===<br>\n",
    "=== epoch:3, train acc:0.868, test acc:0.863 ===<br>\n",
    "=== epoch:4, train acc:0.896, test acc:0.897 ===<br>\n",
    "=== epoch:5, train acc:0.918, test acc:0.903 ===<br>\n",
    "=== epoch:6, train acc:0.927, test acc:0.913 ===<br>\n",
    "=== epoch:7, train acc:0.929, test acc:0.918 ===<br>\n",
    "=== epoch:8, train acc:0.942, test acc:0.924 ===<br>\n",
    "=== epoch:9, train acc:0.948, test acc:0.929 ===<br>\n",
    "=== epoch:10, train acc:0.957, test acc:0.939 ===<br>\n",
    "=============== Final Test Accuracy ===============<br>\n",
    "test acc:0.945<br>\n",
    "\n",
    "<img src='img/train_simpleCNN.png' width='50%' height='50%' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb1ef4e",
   "metadata": {},
   "source": [
    "# <span style=\"color:#2834d4\">CNN 시각화하기</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c3af2",
   "metadata": {},
   "source": [
    "## 층 깊이에 따른 추출 정보 변화\n",
    "\n",
    "<img src='img/cnn_visualizing.png' width='70%' height='70%' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde572c",
   "metadata": {},
   "source": [
    "- 계층이 깊어질수록 추출되는 정보가 추상화됨\n",
    "- 층이 깊어질수록 뉴런이 반응하는 대상이 단순한 모양에서 고급정보로 변화\n",
    "    - 다시말하면, 사물의 의미를 이해하도록 변화하는 것\n",
    "    - 초반에는 단순한 에지에 반응하고, 이어서 텍스처에 반응하고, 더 복잡한 사물의 일부에 반응하도록 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b35a15",
   "metadata": {},
   "source": [
    "# <span style=\"color:#2834d4\">대표적인 CNN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c2336d",
   "metadata": {},
   "source": [
    "## LeNet\n",
    "\n",
    "<img src='img/LeNet.png' width='70%' height='70%' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1848813",
   "metadata": {},
   "source": [
    "- activation function으로 sigmoid 사용\n",
    "- subsampling을 통해 feature map의 크기를 줄임 (max pooling 사용 X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da2668",
   "metadata": {},
   "source": [
    "## AlexNet\n",
    "\n",
    "<img src='img/AlexNet.png' width='70%' height='70%' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bb08c4",
   "metadata": {},
   "source": [
    "- activation function으로 ReLU 사용\n",
    "- max pooling을 통해 feature map의 크기를 줄임\n",
    "- LRN(Local Response Normalization) 이라는 국소적 정규화를 실시하는 계층을 이용\n",
    "- dropout 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a70ea3",
   "metadata": {},
   "source": [
    "# <span style=\"color:#2834d4\">정리</span>\n",
    "\n",
    "- CNN은 지금까지의 완전 연결 계층 네트워크에 합성곱 계층과 풀링 계층을 새로 추가한 것.\n",
    "- 합성곱 계층과 풀링 계층은 이미지를 행렬로 전개하는 함수를 이용하면 간단하고 효율적으로 구현 가능.\n",
    "- CNN을 시각화해보면 계층이 깊어질수록 고급 정보가 추출되는 모습을 확인할 수 있음.\n",
    "- 대표적인 CNN에는 LeNet과 AlexNet이 있음.\n",
    "- 딥러닝의 발전에는 빅데이터와 GPU가 크게 기여함."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
